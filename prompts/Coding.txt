# Onboarding - prompt-design spec

You are a Coding Agent. You will be focused on implementing code as specified in design and task documentation.

Your first project is specified in the .cursor/specs/prompt-design/ folder. You should review the design.md file documented in this folder. Following your review of the design file, you should then look at Task 1 of .cursor/specs/prompt-design/tasks.md, which provides you with the first task for you to implement.

Before you start implementing, I'd like you to ask me at least 5 questions you might have about the requirements for the chat tool, the design, or your first task.

## Responses to questions

1. session_store.py should be stored in the server/tools/ area, but in a new folder server/tools/lib/
2. We should create a standard config.yaml, which can be modified by the user. Section 8.1 of the design.md file provides the standard values.
3. `tabulate1 is fine.
4. Temporary directory under tmp/ is fine.
5. Empty files upon session creation.

If you have any further questions, please ask. Otherwise, proceed to implement.

### Housekeeping

In the server/ folder, you should create a new git repo, to track all the code you've created in the server/ folder. Then commit the code you've made so far. After that, I'd like you set up a remote with `git remote set-url origin git@github-jasonychoong:jasonychoong/retire-server.git`, and then push.

## Task 2

Okay, please proceed to review Task 2 of .cursor/specs/prompt-design/tasks.md, which you will be implementing next. Please ask me at least one question to help you clarify your understanding of this taks.

### Answer to question

1. Preferred provider client library: openai>=1.42.0, google-genai>=1.52.0
2. Environment variable names: OPENAI_API_KEY, GOOGLE_AI_API_KEY

Unless you have any further questions, please proceed to implement Task 2.

## Task 3

Okay, please proceed to review Task 3 of .cursor/specs/prompt-design/tasks.md, which you will be implementing next. Please ask me at least one question to help you clarify your understanding of this taks.

## Task 4

Okay, please proceed to review Task 4 of .cursor/specs/prompt-design/tasks.md, which you will be implementing next. Please ask me at least one question to help you clarify your understanding of this taks.

### Answer to question

Let's keep it flat for now. If you have any further questions, please ask now before starting implementation. Otherwise, proceed to implement task 4.

### New Task 4.3

We have a new subtask, Task 4.3, added to to tasks.md. Please implement this subtask as documented. If you have any questions about it, please ask before you start implementing.

## Task 5

Okay, please proceed to review Task 5 of .cursor/specs/prompt-design/tasks.md, which you will be implementing next. Please ask me at least one question to help you clarify your understanding of this taks.

Design Agent has revised the requirements for Task 5.1. Please re-read it and use this revised design (which now calls for us of prompt_toolkit instead of the more complex Textual library). Implement Task 5.1 ONLY first (and wait to hear from me about task 5.2). Upon completion, DO NOT commit code. I'd like to examine the results to see whether the use of prompt_toolkit is of sufficient value. If not, I will be asking you to revert the code changes. 

1. Yes, when I run the `printf` statement, I get blue text.
2. The prompt doesn't actually appear in the TextArea above. And when the assistant finishes their response, the user prompt does not appear properly (no "You > "), and the caret just appears at the of the assistant text, rather than on a new line.
3. Page up/down, arrow up/down doesn't do anything.

I've attached the tui logs.

Okay, this is not working out. Please revert all code changes back to the last commit. Then read Task 5.1 from the tasks.md file again. It has been revised. Please let me know if you have any questions.

Here's what I'm seeing.
1. For the user prompt, what I get is "You> " being shown in green, but when I, as the user types the text, I get white text (rather than green).
2. When the response from the model comes back, it comes back in white first. Then there's an identical response preambled by "Assistant: " that's in blue. The former white response needs to be removed.

Go ahead and commit the changes for Task 5.1. Once you've done that, please proceed to implement Task 5.2.

### Housekeeping

I think we're good for Task 5. Please go ahead and commit and push the server/ folder.

# completeness-tools spec kick off

Let's take a pause on the current prompt infrastructure. I'd like you to do the following:

1. Review the new design spec, .cursor/specs/prompt-design/design-completeness-tools.md.
2. Review the new task spec, .cursor/specs/prompt-design/tasks-completeness-tools.md, for Task 1 ONLY.
3. Create a branch in the server/ folder called, `completeness-tools`. All code changes in server/ for all tasks described in the .cursor/specs/prompt-design/tasks-completeness-tools.md file will be committed onto this branch.

Then, ask me at least three questions about the design spec, and/or Task 1 from the task spec to help you better understand the ask.

## Answers to questions

1. Let's just omit it for now until we find a use case for it.
2. Help me understand how the `SessionStore` abstraction is structured and is instantiated. My sense is the new helpers could end up being general purpose extensions to the `SessionStore` abstraction. What I don't know is whether we extend the existng `SessionStore` abstraction with new methods, or whether we should create new subclasses of `SessionSstore` for this kind of use case. Perhaps you can provide me with more details so that we can collaboratively figure out how to implement these helpers.
3. Simple file appends is fine. This is for a prototype which will be called one at a time. 

Let's iterate on question 2, but if you have any other new questions, or have follow-ups on 1 and 3, please raise them.

## Housekeeping and task 2

I think we're good with what you've implemented for Task 1. Please go ahead and commit into the `completeness-tools` branch. Then push. Then I'd like you to review Task 2. After this review, please ask me at least 2 questions to help you understand the ask in Task 2.

### Answers to clarifying questions
1. Yes, infer the session ID from the same environment/context that the CLI uses.
2. Have information_query return the records in raw append/chronological order with no extra sorting/filtering.
Unless you have any other questions, please proceed to implement.

## Housekeeping and task 3

I think we're good with what you've implemented for Task 2. Please go ahead and commit into the `completeness-tools` branch. Then push. Then I'd like you to review Task 3. After this review, please ask me at least one question to help you understand the ask in Task 3.

### Answers to question

Manual test instructions is fine.

### Questions during manual testing

In server/tools/.chat/sessions/dc189f3b-7c9b-4f34-9577-eb7422de7f17/history.json, I have a "tool result was too large" error. I believe this means that we're hitting the Strands Agent limits right? Is this simply a case of the window_size being too small? If I was to change my window_size in the middle of an active session (by quitting the chat app, and launching it again with a new window_size), will subsequent tool calls work for the current session?
>>>> Defer - potentially wait until the TUI is put in place

### Minor adjustments

* In the multi-turn interaction, when the assistant content is printed, please add an "Assistant> " prefix in a similar way there is a "You> " prompt for user input.
