## Data Completeness Tools – Design Spec

### 1. Overview and Goals

This design specifies a small set of **data-completeness tools** and a corresponding system-prompt behavior that allow the retirement-planning agent to:

- **Elicit and persist** structured information about a user’s retirement situation across a set of **essential planning topics** (income, healthcare, housing, tax, longevity, long-term care, lifestyle, and estate planning).
- **Continuously and silently track completeness** of information across those topics, regardless of which specific topics the user chooses to discuss.
- **Periodically rehydrate** that information so the model can reason about **gaps** in coverage.
- **Record per-topic completeness scores** (0–100) that can be consumed by non-chat experiences (e.g., a completeness chart) outside the LLM.

These tools are used by the CLI-based chat prototype defined in the main prompt-design spec, and all persistence is **local and session-scoped** under `server/tools/.chat/sessions/<session-id>/`.

### 2. Non-Goals

- No cross-session or cross-user memory; all data is scoped to a **single session ID**.
- No production-grade privacy, encryption, or access control; local files are sufficient for this prototype.
- No complex querying or analytics; JSON/JSONL files and in-memory filtering are adequate.
- No user-facing visualization in this spec; the completeness scores are intended for use by other layers (e.g., future UI) but are not surfaced directly by the assistant in numeric form.

---

### 3. Canonical Topic Enumeration

All tools in this design share a **strict set of topic identifiers** derived from the “Essential Topics” document. These topic IDs are used in the tool APIs and persisted data.

Canonical topics (IDs and human-readable labels):

- `income_cash_flow` – Income Stability & Cash Flow (The Engine)
- `healthcare_medicare` – Healthcare & Medicare Strategy (The Shield)
- `housing_geography` – Housing & Geography (The Anchor)
- `tax_efficiency_rmds` – Tax Efficiency & RMDs (The Filter)
- `longevity_inflation` – Longevity & Inflation Risk (The Horizon)
- `long_term_care` – Long-Term Care (The "Black Swan")
- `lifestyle_purpose` – Lifestyle Design & Purpose (The "Why")
- `estate_planning` – Estate Planning (The Legacy)

**Requirements:**

- Tools MUST accept `topic` values only from this enum.
- Where a user statement clearly spans multiple topics (e.g., a decision that affects both `income_cash_flow` and `tax_efficiency_rmds`), the model may:
  - Either make **multiple tool calls** (one per topic), or
  - Use a tool parameter that supports multiple topics (see tool design below).

---

### 4. Persistence Model and File Layout

All data created by these tools is scoped to a **single chat session** and is stored under:

- Base path: `server/tools/.chat/sessions/<session-id>/`

Recommended files (the Coding Agent may adjust exact filenames if needed, but should preserve semantics):

- `information.jsonl` – append-only log of **information records**.
- `completeness.jsonl` – append-only log of **completeness snapshots**.

#### 4.1 Information Record Schema

Each line in `information.jsonl` is a JSON object with the following shape:

- `id` (string, optional): Tool-generated unique ID for this record (e.g., UUID or monotonic counter).
- `session_id` (string): The session this record belongs to.
- `topic` (string, required): One of the canonical topic IDs defined above.
- `subtopic` (string or null): Free-form label that describes the sub-area (e.g., `"social_security_claiming"`, `"medigap_vs_medicare_advantage"`).
- `fact_type` (string): Short machine-friendly label summarizing what kind of fact this is (e.g., `"target_retirement_age"`, `"mortgage_status"`).
- `value` (string): Concise natural-language summary of the information as understood by the model.
- `confidence` (number, 0.0–1.0): Model’s confidence that the `value` correctly captures the user’s intent.
- `created_at` (string, ISO8601): Timestamp recorded by the tool implementation at write-time.

Design notes:

- **Session scoping**: `session_id` should be inferred from the surrounding chat context (e.g., by the Chat Agent API) rather than passed from the LLM as an argument.
- **Timestamp**: The timestamp should be generated by the tool implementation on the server side; the model does not need to supply it.

#### 4.2 Completeness Snapshot Schema

Each line in `completeness.jsonl` is a JSON object with the following shape:

- `session_id` (string): The session this snapshot belongs to.
- `scores` (array of objects):
  - Each object:
    - `topic` (string): Canonical topic ID.
    - `score` (integer 0–100): Model’s current assessment of completeness for that topic.
    - `reason` (string, optional): Brief natural-language explanation of why the score changed or how it was determined.
- `created_at` (string, ISO8601): Timestamp recorded by the tool implementation at write-time.

Design notes:

- The model may choose to send scores for **all topics** or only the topics whose completeness changed since the last snapshot; the implementation should accept either and persist exactly what is provided.
- The **consumer** of these snapshots (e.g., a UI) is responsible for computing the latest score per topic by reading the file and taking the most recent entry per topic.

---

### 5. Tool 1 – `information`

#### 5.1 Purpose

Allow the agent to **persist new, discrete pieces of user information** about retirement-related circumstances, goals, or constraints, tied to one canonical topic (and optional subtopic).

The system prompt instructs the model to call this tool whenever it learns a **new, meaningful fact** or when the user corrects a previously captured fact.

#### 5.2 Proposed Python Interface

- Module: `server/agents/tools/information.py`
- Tool function (example):

```python
@tool
def information(
    topic: str,
    value: str,
    subtopic: str | None = None,
    fact_type: str | None = None,
    confidence: float = 0.9,
) -> str:
    """
    Persist a new piece of retirement-planning information for this session.

    Args:
        topic: Canonical topic ID (e.g., "income_cash_flow", "healthcare_medicare").
        value: Concise natural-language summary of the information just learned.
        subtopic: Optional free-form label for the subtopic (e.g., "social_security_claiming").
        fact_type: Optional machine-friendly label describing the kind of fact (e.g., "target_retirement_age").
        confidence: Model's confidence (0.0–1.0) that the value accurately reflects the user's situation or intent.

    Returns:
        A short confirmation message or identifier for the stored record.
    """
```

#### 5.3 Behavioral Requirements

- **Topic validation**: Implementation must validate `topic` against the canonical enum. Invalid topics should result in a clear error (for debugging) rather than silent acceptance.
- **Granularity**:
  - Prefer **one tool call per distinct fact**.
  - If a user provides multiple independent facts in one sentence (e.g., retirement age and desired location), the model should ideally make multiple `information` calls.
- **Corrections/updates**:
  - If the user corrects an earlier statement, the model should make a **new** `information` call summarizing the corrected fact; the historical record is additive.
- **Session scoping**:
  - The tool should infer the current session from the calling context and write to `information.jsonl` under that session’s directory.

---

### 6. Tool 2 – `information_query`

#### 6.1 Purpose

Provide the model with a **snapshot of all persisted information** for the current session so it can:

- Review what has already been captured.
- Identify gaps in coverage across topics.
- Decide whether to adjust completeness scores.

#### 6.2 Proposed Python Interface

- Module: `server/agents/tools/information_query.py`
- Tool function (example):

```python
@tool
def information_query() -> list[dict]:
    """
    Fetch all persisted information records for the current session.

    Returns:
        A list of information records, each matching the schema written to information.jsonl:
            {
                "id": ...,
                "session_id": ...,
                "topic": ...,
                "subtopic": ...,
                "fact_type": ...,
                "value": ...,
                "confidence": ...,
                "created_at": ...
            }
    """
```

#### 6.3 Behavioral Requirements

- **No arguments** are required; session identity comes from the surrounding context.
- The tool:
  - Reads `information.jsonl` for the current session (if present).
  - Parses each line into a JSON object.
  - Returns all records as a list (empty list if no information has been captured yet).
- The tool should **not mutate** any state; it is read-only.

---

### 7. Tool 3 – `completeness`

#### 7.1 Purpose

Allow the model to persist **per-topic completeness scores** (0–100) that represent how confident it is that it has **enough information** to start building a reasonably detailed plan for that topic.

The system prompt instructs the model to:

- Periodically call `information_query`.
- Reassess completeness per topic.
- Call `completeness` when scores have **materially changed** (e.g., by ~10 points or more) or after several new `information` calls.

#### 7.2 Proposed Python Interface

- Module: `server/agents/tools/completeness.py`
- Tool function (example):

```python
from typing import List, Dict, Any


@tool
def completeness(scores: List[Dict[str, Any]]) -> str:
    """
    Persist a completeness snapshot for one or more topics for this session.

    Args:
        scores: A list of objects, each with:
            - "topic": canonical topic ID (e.g., "income_cash_flow").
            - "score": integer 0–100, representing information completeness for that topic.
            - "reason": optional short explanation of why the score is at this level
              or what changed since the previous score.

    Returns:
        A short confirmation message or identifier for the stored snapshot.
    """
```

#### 7.3 Behavioral Requirements

- The tool:
  - Validates each `topic` against the canonical enum.
  - Validates each `score` is between 0 and 100 (inclusive).
  - Writes a single completeness snapshot entry to `completeness.jsonl`, including:
    - `session_id`,
    - the raw `scores` list provided by the model,
    - `created_at` timestamp.
- The tool does **not** compute deltas or enforce thresholds; those behaviors are driven by the system prompt and model.

---

### 8. System Prompt Alignment

The `completeness.txt` system prompt (under `server/tools/.chat/system-prompts/`) must:

- Use the same persona and target audience as the `readiness.txt` prompt (retirement consultant for US-based, mid-to-late career workers).
- Encourage the model to:
  - Ask which topics are most important to the user and prioritize those.
  - Dive deeper on selected topics with focused questions and explanations.
  - Call `information` whenever a new, meaningful fact is learned or corrected.
  - Call `information_query` roughly every 3–5 `information` calls or after substantial changes in understanding.
  - Call `completeness` when per-topic scores change materially (on the order of 10 points or more).
- Treat completeness scores as **internal**:
  - Do not surface numeric scores directly to the user in chat.
  - Use them implicitly to guide which topics to revisit or explore next.

---

### 9. Testing Considerations

The Coding Agent should provide unit tests that cover at least:

- `information`:
  - Writing valid records to `information.jsonl` for each canonical topic.
  - Validation failures on invalid topics.
  - Behavior when called multiple times (append-only semantics).
- `information_query`:
  - Behavior when no file exists (returns empty list).
  - Behavior when the file exists with several records (returns parsed list).
- `completeness`:
  - Validation of topic IDs and score ranges.
  - Correct writing of snapshots to `completeness.jsonl`.

These tests can be placed under the existing `server/tests/` structure, following the patterns established for other tools and persistence components.

---

### 10. CLI Monitors – Completeness and Profile Views

In addition to the tools above, this design introduces two **read-only CLI utilities** that consume `information.jsonl` and `completeness.jsonl` to provide a live view of the user’s planning profile and topic completeness while a chat session is running.

These tools are **not** required for the agent to function, but they are important for:

- Demonstrating completeness behavior side-by-side with the chat.
- Allowing users (and designers) to observe how information and completeness evolve over time.

#### 10.1 Session Resolution for Monitors

Both CLIs follow the same rules:

- Default session:
  - If `--session <UUID>` is **not** provided, they resolve the session to monitor using the session marked `is_current: true` in `server/tools/.chat/sessions/index.json` (i.e., the same “current” session that `chat --list-sessions` highlights).
- Explicit session:
  - If `--session <UUID>` is provided, they monitor the specified session ID regardless of `is_current`.
- Environment:
  - They **do not rely on** `RETIRE_CURRENT_SESSION_ID`; that variable remains an internal mechanism for the `chat` CLI.

If the target session directory or JSONL files are missing or empty, the tools should display an “awaiting data…” message and continue polling.

#### 10.2 `server/tools/completeness` – Live Topic Completeness Monitor

Purpose:

- Provide a **live, terminal-based visualization** of per-topic completeness scores for a single session, suitable for running alongside the chat CLI in a separate terminal window.
- Optionally suggest a **pre-crafted prompt** for the user to copy/paste into the chat when they choose to explore a specific topic more deeply.

Behavior:

- Command-line interface (conceptual):
  - `server/tools/completeness [--session <UUID>]`
- Polling loop:
  - Every ~2 seconds, examine the session’s `completeness.jsonl` (e.g., via mtime or by re-reading; exact mechanism up to Coding Agent).
  - If the file does not exist or has no entries yet, clear the screen and print a simple message such as:
    - `awaiting data...` (and continue polling).
  - If entries exist:
    - Read all snapshots and compute the **latest score per topic** by taking the most recent `score` for each topic across all entries.
    - Clear the terminal using simple ANSI sequences (e.g., `\x1b[2J\x1b[H`).
    - Render one line per canonical topic in a fixed order:
      1. `income_cash_flow`
      2. `healthcare_medicare`
      3. `housing_geography`
      4. `tax_efficiency_rmds`
      5. `longevity_inflation`
      6. `long_term_care`
      7. `lifestyle_purpose`
      8. `estate_planning`
    - For each topic, display a **text arrow** whose length encodes the latest score:
      - A `|` character aligned in a column across all lines.
      - Followed by a run of `=` characters and a final `>` tip.
      - Each character (either `=` or `>`) represents **5 points** of completeness.
      - After the arrow, print a space and the numeric score.
      - A score of 0 is displayed as `| 0` with no arrow body.
    - Example layout (monospaced alignment implied):
      - `1. income_cash_flow     |================> 85`
      - `2. healthcare_medicare  |========> 45`
      - `3. housing_geography    |===========> 60`
      - `4. tax_efficiency_rmds  | 0`
      - `5. longevity_inflation  | 0`
      - `6. long_term_care       | 0`
      - `7. lifestyle_purpose    | 0`
      - `8. estate_planning      |=========> 50`
- Topic exploration prompt:
  - After the topic lines, print a prompt:
    - `Help me explore a specific topic (enter number 1-8)> `
  - If the user enters a number 1–8:
    - The tool does **not** attempt to inject into a running chat process.
    - Instead, it prints a **recommended user prompt string** tailored to that topic, which the user can copy/paste into their existing `server/tools/chat` terminal. The Design Agent will provide example phrasing per topic in a future prompt-design iteration.
  - The monitor continues running; the user can continue to watch updates and optionally select topics again.
- Exit:
  - The process runs until the user terminates it with `Ctrl-C` or `Ctrl-D`; it does not exit automatically.

#### 10.3 `server/tools/profile` – Live Information Profile Viewer

Purpose:

- Provide a **structured, continuously updating view** of all facts the agent has captured about the user, grouped by topic and subtopic, based on `information.jsonl`.

Behavior:

- Command-line interface (conceptual):
  - `server/tools/profile [--session <UUID>]`
- Polling loop:
  - Every ~2 seconds, examine the session’s `information.jsonl`.
  - If the file does not exist or has no entries yet, clear the screen and print `awaiting data...`, then continue polling.
  - If entries exist:
    - Read all records and group them by:
      - `topic` (canonical ID),
      - then `subtopic` (string or `None`),
      - then chronological order of records within each subtopic.
    - Clear the screen via ANSI codes.
    - Render a hierarchical view similar to:
      - `income_cash_flow`
      - `    retirement_timing`
      - `        Goal: User is considering retiring next year`
      - `        Goal: User and spouse plan to stop working around May next year, with no work income afterward (conservative assumption).`
      - `    ages`
      - `        Fact: User is 64; spouse is 6 years younger (age 58).`
      - `    spending`
      - `        Goal: target retirement spending is about $100,000 per year (today's dollars).`
      - `    social_security`
      - `        Goal: User and spouse plan to claim Social Security at age 70 and expect to receive near-maximum benefits as high earners.`
      - `    assets`
      - `        Goal: User has about $2M in liquid/investable assets and about $2M net equity in property.`
      - `    asset_breakdown`
      - `        Fact: Liquid assets: ~$0.7M taxable, ~$1.2M in 401k/IRA, ~$100k in Roth. Property and debt details…`
      - `housing_geography`
      - `    future_moves`
      - `        Goal: User plans to sell one rental property in about 2 years.`
      - `healthcare_medicare`
      - `    priority`
      - `        Preference: User wants to focus on healthcare insurance options and cost implications given early retirement.`
    - Label lines based on `fact_type` or the nature of the entry:
      - For example: `Goal:`, `Fact:`, `Preference:` based on simple heuristics or the `fact_type` string.
- Exit:
  - As with the completeness monitor, the profile viewer runs until interrupted by the user; it does not exit automatically.

