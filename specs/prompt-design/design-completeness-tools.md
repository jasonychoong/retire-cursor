## Data Completeness Tools – Design Spec

### 1. Overview and Goals

This design specifies a small set of **data-completeness tools** and a corresponding system-prompt behavior that allow the retirement-planning agent to:

- **Elicit and persist** structured information about a user’s retirement situation across a set of **essential planning topics** (income, healthcare, housing, tax, longevity, long-term care, lifestyle, and estate planning).
- **Continuously and silently track completeness** of information across those topics, regardless of which specific topics the user chooses to discuss.
- **Periodically rehydrate** that information so the model can reason about **gaps** in coverage.
- **Record per-topic completeness scores** (0–100) that can be consumed by non-chat experiences (e.g., a completeness chart) outside the LLM.

These tools are used by the CLI-based chat prototype defined in the main prompt-design spec, and all persistence is **local and session-scoped** under `server/tools/.chat/sessions/<session-id>/`.

### 2. Non-Goals

- No cross-session or cross-user memory; all data is scoped to a **single session ID**.
- No production-grade privacy, encryption, or access control; local files are sufficient for this prototype.
- No complex querying or analytics; JSON/JSONL files and in-memory filtering are adequate.
- No user-facing visualization in this spec; the completeness scores are intended for use by other layers (e.g., future UI) but are not surfaced directly by the assistant in numeric form.

---

### 3. Canonical Topic Enumeration

All tools in this design share a **strict set of topic identifiers** derived from the “Essential Topics” document. These topic IDs are used in the tool APIs and persisted data.

Canonical topics (IDs and human-readable labels):

- `income_cash_flow` – Income Stability & Cash Flow (The Engine)
- `healthcare_medicare` – Healthcare & Medicare Strategy (The Shield)
- `housing_geography` – Housing & Geography (The Anchor)
- `tax_efficiency_rmds` – Tax Efficiency & RMDs (The Filter)
- `longevity_inflation` – Longevity & Inflation Risk (The Horizon)
- `long_term_care` – Long-Term Care (The "Black Swan")
- `lifestyle_purpose` – Lifestyle Design & Purpose (The "Why")
- `estate_planning` – Estate Planning (The Legacy)

**Requirements:**

- Tools MUST accept `topic` values only from this enum.
- Where a user statement clearly spans multiple topics (e.g., a decision that affects both `income_cash_flow` and `tax_efficiency_rmds`), the model may:
  - Either make **multiple tool calls** (one per topic), or
  - Use a tool parameter that supports multiple topics (see tool design below).

---

### 4. Persistence Model and File Layout

All data created by these tools is scoped to a **single chat session** and is stored under:

- Base path: `server/tools/.chat/sessions/<session-id>/`

Recommended files (the Coding Agent may adjust exact filenames if needed, but should preserve semantics):

- `information.jsonl` – append-only log of **information records**.
- `completeness.jsonl` – append-only log of **completeness snapshots**.

#### 4.1 Information Record Schema

Each line in `information.jsonl` is a JSON object with the following shape:

- `id` (string, optional): Tool-generated unique ID for this record (e.g., UUID or monotonic counter).
- `session_id` (string): The session this record belongs to.
- `topic` (string, required): One of the canonical topic IDs defined above.
- `subtopic` (string or null): Free-form label that describes the sub-area (e.g., `"social_security_claiming"`, `"medigap_vs_medicare_advantage"`).
- `fact_type` (string): Short machine-friendly label summarizing what kind of fact this is (e.g., `"target_retirement_age"`, `"mortgage_status"`).
- `value` (string): Concise natural-language summary of the information as understood by the model.
- `confidence` (number, 0.0–1.0): Model’s confidence that the `value` correctly captures the user’s intent.
- `created_at` (string, ISO8601): Timestamp recorded by the tool implementation at write-time.

Design notes:

- **Session scoping**: `session_id` should be inferred from the surrounding chat context (e.g., by the Chat Agent API) rather than passed from the LLM as an argument.
- **Timestamp**: The timestamp should be generated by the tool implementation on the server side; the model does not need to supply it.

#### 4.2 Completeness Snapshot Schema

Each line in `completeness.jsonl` is a JSON object with the following shape:

- `session_id` (string): The session this snapshot belongs to.
- `scores` (array of objects):
  - Each object:
    - `topic` (string): Canonical topic ID.
    - `score` (integer 0–100): Model’s current assessment of completeness for that topic.
    - `reason` (string, optional): Brief natural-language explanation of why the score changed or how it was determined.
- `created_at` (string, ISO8601): Timestamp recorded by the tool implementation at write-time.

Design notes:

- The model may choose to send scores for **all topics** or only the topics whose completeness changed since the last snapshot; the implementation should accept either and persist exactly what is provided.
- The **consumer** of these snapshots (e.g., a UI) is responsible for computing the latest score per topic by reading the file and taking the most recent entry per topic.

---

### 5. Tool 1 – `information`

#### 5.1 Purpose

Allow the agent to **persist new, discrete pieces of user information** about retirement-related circumstances, goals, or constraints, tied to one canonical topic (and optional subtopic).

The system prompt instructs the model to call this tool whenever it learns a **new, meaningful fact** or when the user corrects a previously captured fact.

#### 5.2 Proposed Python Interface

- Module: `server/agents/tools/information.py`
- Tool function (example):

```python
@tool
def information(
    topic: str,
    value: str,
    subtopic: str | None = None,
    fact_type: str | None = None,
    confidence: float = 0.9,
) -> str:
    """
    Persist a new piece of retirement-planning information for this session.

    Args:
        topic: Canonical topic ID (e.g., "income_cash_flow", "healthcare_medicare").
        value: Concise natural-language summary of the information just learned.
        subtopic: Optional free-form label for the subtopic (e.g., "social_security_claiming").
        fact_type: Optional machine-friendly label describing the kind of fact (e.g., "target_retirement_age").
        confidence: Model's confidence (0.0–1.0) that the value accurately reflects the user's situation or intent.

    Returns:
        A short confirmation message or identifier for the stored record.
    """
```

#### 5.3 Behavioral Requirements

- **Topic validation**: Implementation must validate `topic` against the canonical enum. Invalid topics should result in a clear error (for debugging) rather than silent acceptance.
- **Granularity**:
  - Prefer **one tool call per distinct fact**.
  - If a user provides multiple independent facts in one sentence (e.g., retirement age and desired location), the model should ideally make multiple `information` calls.
- **Corrections/updates**:
  - If the user corrects an earlier statement, the model should make a **new** `information` call summarizing the corrected fact; the historical record is additive.
- **Session scoping**:
  - The tool should infer the current session from the calling context and write to `information.jsonl` under that session’s directory.

---

### 6. Tool 2 – `information_query`

#### 6.1 Purpose

Provide the model with a **snapshot of all persisted information** for the current session so it can:

- Review what has already been captured.
- Identify gaps in coverage across topics.
- Decide whether to adjust completeness scores.

#### 6.2 Proposed Python Interface

- Module: `server/agents/tools/information_query.py`
- Tool function (example):

```python
@tool
def information_query() -> list[dict]:
    """
    Fetch all persisted information records for the current session.

    Returns:
        A list of information records, each matching the schema written to information.jsonl:
            {
                "id": ...,
                "session_id": ...,
                "topic": ...,
                "subtopic": ...,
                "fact_type": ...,
                "value": ...,
                "confidence": ...,
                "created_at": ...
            }
    """
```

#### 6.3 Behavioral Requirements

- **No arguments** are required; session identity comes from the surrounding context.
- The tool:
  - Reads `information.jsonl` for the current session (if present).
  - Parses each line into a JSON object.
  - Returns all records as a list (empty list if no information has been captured yet).
- The tool should **not mutate** any state; it is read-only.

---

### 7. Tool 3 – `completeness`

#### 7.1 Purpose

Allow the model to persist **per-topic completeness scores** (0–100) that represent how confident it is that it has **enough information** to start building a reasonably detailed plan for that topic.

The system prompt instructs the model to:

- Periodically call `information_query`.
- Reassess completeness per topic.
- Call `completeness` when scores have **materially changed** (e.g., by ~10 points or more) or after several new `information` calls.

#### 7.2 Proposed Python Interface

- Module: `server/agents/tools/completeness.py`
- Tool function (example):

```python
from typing import List, Dict, Any


@tool
def completeness(scores: List[Dict[str, Any]]) -> str:
    """
    Persist a completeness snapshot for one or more topics for this session.

    Args:
        scores: A list of objects, each with:
            - "topic": canonical topic ID (e.g., "income_cash_flow").
            - "score": integer 0–100, representing information completeness for that topic.
            - "reason": optional short explanation of why the score is at this level
              or what changed since the previous score.

    Returns:
        A short confirmation message or identifier for the stored snapshot.
    """
```

#### 7.3 Behavioral Requirements

- The tool:
  - Validates each `topic` against the canonical enum.
  - Validates each `score` is between 0 and 100 (inclusive).
  - Writes a single completeness snapshot entry to `completeness.jsonl`, including:
    - `session_id`,
    - the raw `scores` list provided by the model,
    - `created_at` timestamp.
- The tool does **not** compute deltas or enforce thresholds; those behaviors are driven by the system prompt and model.

---

### 8. System Prompt Alignment

The `completeness.txt` system prompt (under `server/tools/.chat/system-prompts/`) must:

- Use the same persona and target audience as the `readiness.txt` prompt (retirement consultant for US-based, mid-to-late career workers).
- Encourage the model to:
  - Ask which topics are most important to the user and prioritize those.
  - Dive deeper on selected topics with focused questions and explanations.
  - Call `information` whenever a new, meaningful fact is learned or corrected.
  - Call `information_query` roughly every 3–5 `information` calls or after substantial changes in understanding.
  - Call `completeness` when per-topic scores change materially (on the order of 10 points or more).
- Treat completeness scores as **internal**:
  - Do not surface numeric scores directly to the user in chat.
  - Use them implicitly to guide which topics to revisit or explore next.

---

### 9. Testing Considerations

The Coding Agent should provide unit tests that cover at least:

- `information`:
  - Writing valid records to `information.jsonl` for each canonical topic.
  - Validation failures on invalid topics.
  - Behavior when called multiple times (append-only semantics).
- `information_query`:
  - Behavior when no file exists (returns empty list).
  - Behavior when the file exists with several records (returns parsed list).
- `completeness`:
  - Validation of topic IDs and score ranges.
  - Correct writing of snapshots to `completeness.jsonl`.

These tests can be placed under the existing `server/tests/` structure, following the patterns established for other tools and persistence components.


